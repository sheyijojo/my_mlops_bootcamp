{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97420ff2",
   "metadata": {},
   "source": [
    "Homework goal is to train a ride duration prediction model using data from NYC taxi dataset 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c86e3d",
   "metadata": {},
   "source": [
    "ENV: I am using Github codespaces and Anaconda to set up my environment. Another option is to use AWS Linux env, but I would not be using that. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55bd006",
   "metadata": {},
   "source": [
    "### Dataset source\n",
    "\n",
    "The New York and Limousine Commission and I am using the yellow taxi, use the dataset for January and February 2023\n",
    "`https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet`\n",
    "\n",
    "`https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f57602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # working with tabular data\n",
    "import numpy as np\n",
    "import pickle # for machine learning models\n",
    "import seaborn as sns # visualization\n",
    "import matplotlib.pyplot as plt # visualization\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer # Machine Learning\n",
    "from sklearn.linear_model import LinearRegression # Machine Learning\n",
    "from sklearn.linear_model import Lasso # Regularization\n",
    "from sklearn.linear_model import Ridge # Regularization\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import mean_squared_error # Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5070e716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cd02a1",
   "metadata": {},
   "source": [
    "Download the JAN and FEB 2023 dataset using wget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c8f38c1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-27 00:18:53--  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 52.85.39.153, 52.85.39.97, 52.85.39.117, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|52.85.39.153|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 47673370 (45M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘yellow_tripdata_2023-01.parquet.2’\n",
      "\n",
      "yellow_tripdata_202 100%[===================>]  45.46M  97.0MB/s    in 0.5s    \n",
      "\n",
      "2024-05-27 00:18:54 (97.0 MB/s) - ‘yellow_tripdata_2023-01.parquet.2’ saved [47673370/47673370]\n",
      "\n",
      "--2024-05-27 00:18:54--  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet\n",
      "Reusing existing connection to d37ci6vzurychx.cloudfront.net:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 47748012 (46M) [application/x-www-form-urlencoded]\n",
      "Saving to: ‘yellow_tripdata_2023-02.parquet.2’\n",
      "\n",
      "yellow_tripdata_202 100%[===================>]  45.54M   107MB/s    in 0.4s    \n",
      "\n",
      "2024-05-27 00:18:54 (107 MB/s) - ‘yellow_tripdata_2023-02.parquet.2’ saved [47748012/47748012]\n",
      "\n",
      "FINISHED --2024-05-27 00:18:54--\n",
      "Total wall clock time: 1.1s\n",
      "Downloaded: 2 files, 91M in 0.9s (102 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet  https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6176f2f",
   "metadata": {},
   "source": [
    "### Read the data in dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "133affa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_jan= pd.read_parquet('yellow_tripdata_2023-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2c9d3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:32:10</td>\n",
       "      <td>2023-01-01 00:40:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:55:08</td>\n",
       "      <td>2023-01-01 01:01:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>43</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:25:04</td>\n",
       "      <td>2023-01-01 00:37:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>14.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01 00:03:48</td>\n",
       "      <td>2023-01-01 00:13:25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12.1</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:10:29</td>\n",
       "      <td>2023-01-01 00:21:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>107</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2023-01-01 00:32:10   2023-01-01 00:40:36              1.0   \n",
       "1         2  2023-01-01 00:55:08   2023-01-01 01:01:27              1.0   \n",
       "2         2  2023-01-01 00:25:04   2023-01-01 00:37:49              1.0   \n",
       "3         1  2023-01-01 00:03:48   2023-01-01 00:13:25              0.0   \n",
       "4         2  2023-01-01 00:10:29   2023-01-01 00:21:19              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           0.97         1.0                  N           161           141   \n",
       "1           1.10         1.0                  N            43           237   \n",
       "2           2.51         1.0                  N            48           238   \n",
       "3           1.90         1.0                  N           138             7   \n",
       "4           1.43         1.0                  N           107            79   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2          9.3   1.00      0.5        0.00           0.0   \n",
       "1             1          7.9   1.00      0.5        4.00           0.0   \n",
       "2             1         14.9   1.00      0.5       15.00           0.0   \n",
       "3             1         12.1   7.25      0.5        0.00           0.0   \n",
       "4             1         11.4   1.00      0.5        3.28           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                    1.0         14.30                   2.5         0.00  \n",
       "1                    1.0         16.90                   2.5         0.00  \n",
       "2                    1.0         34.90                   2.5         0.00  \n",
       "3                    1.0         20.85                   0.0         1.25  \n",
       "4                    1.0         19.68                   2.5         0.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellow_jan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337ab5a7",
   "metadata": {},
   "source": [
    "### get the number of columns using info \n",
    "we have 19 columns in here for jan data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f47d68c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3066766 entries, 0 to 3066765\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int64         \n",
      " 1   tpep_pickup_datetime   datetime64[ns]\n",
      " 2   tpep_dropoff_datetime  datetime64[ns]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   PULocationID           int64         \n",
      " 8   DOLocationID           int64         \n",
      " 9   payment_type           int64         \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  airport_fee            float64       \n",
      "dtypes: datetime64[ns](2), float64(12), int64(4), object(1)\n",
      "memory usage: 444.6+ MB\n"
     ]
    }
   ],
   "source": [
    "yellow_jan.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101db969",
   "metadata": {},
   "source": [
    "## Create a duration column to calculate the duration of a ride in minutes.\n",
    "\n",
    "Take a look at the datatype of this duration which is in datetime54"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899c6950",
   "metadata": {},
   "source": [
    "## What are Lambdas in python\n",
    "\n",
    "```md\n",
    "- In Python, a lambda function is a small anonymous function.  \n",
    "- Lambda functions are useful when you need a simple function for a short period of time and don't want to define a full function using the def keyword.\n",
    "- We can apply a lambda function to both the columns and rows of the Pandas data frame.\n",
    "\n",
    "```\n",
    "\n",
    "`https://www.geeksforgeeks.org/applying-lambda-functions-to-pandas-dataframe/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "692875dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_jan['duration'] = yellow_jan.tpep_dropoff_datetime - yellow_jan.tpep_pickup_datetime\n",
    "\n",
    "## convert to minutes as some data points are sometimes in day, use lambda function as td using the total_seconds function\n",
    "\n",
    "yellow_jan.duration = yellow_jan.duration.apply(lambda td: td.total_seconds()/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763c025f",
   "metadata": {},
   "source": [
    "## Select Variable for prediction \n",
    "```md\n",
    "\n",
    "## I need to give information on what these variables\n",
    "\n",
    "- We will be using the `PULocationID ` and the `DOLocationID` for this prediciton.\n",
    "\n",
    "- However they are `int64` data type and we need a `strings(object)` to make it a categorical datatype.\n",
    "\n",
    "- why covert to PU & DO categorical?, when trip distance is already numerical\n",
    "\n",
    "``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ececd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert PU and DO into categorical variable\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "\n",
    "yellow_jan[categorical] = yellow_jan[categorical].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783876e6",
   "metadata": {},
   "source": [
    "```md\n",
    "Now the PU and DO dataype has been changed to objects(string) datatype\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2d4ce41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3066766 entries, 0 to 3066765\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int64         \n",
      " 1   tpep_pickup_datetime   datetime64[ns]\n",
      " 2   tpep_dropoff_datetime  datetime64[ns]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   PULocationID           object        \n",
      " 8   DOLocationID           object        \n",
      " 9   payment_type           int64         \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  airport_fee            float64       \n",
      " 19  duration               float64       \n",
      "dtypes: datetime64[ns](2), float64(13), int64(2), object(3)\n",
      "memory usage: 468.0+ MB\n"
     ]
    }
   ],
   "source": [
    "yellow_jan.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06a0cba",
   "metadata": {},
   "source": [
    "## check the distribution of the duration numerical variable and see how skewed it is.\n",
    "\n",
    "```md\n",
    "What is the standard deviation of the duration variable?\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa404ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.066766e+06</td>\n",
       "      <td>2.995023e+06</td>\n",
       "      <td>3.066766e+06</td>\n",
       "      <td>2.995023e+06</td>\n",
       "      <td>3.066766e+06</td>\n",
       "      <td>3.066766e+06</td>\n",
       "      <td>3.066766e+06</td>\n",
       "      <td>3.066766e+06</td>\n",
       "      <td>3.066766e+06</td>\n",
       "      <td>3.066766e+06</td>\n",
       "      <td>3.066766e+06</td>\n",
       "      <td>3.066766e+06</td>\n",
       "      <td>2.995023e+06</td>\n",
       "      <td>2.995023e+06</td>\n",
       "      <td>3.066766e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.730215e+00</td>\n",
       "      <td>1.362532e+00</td>\n",
       "      <td>3.847342e+00</td>\n",
       "      <td>1.497440e+00</td>\n",
       "      <td>1.194483e+00</td>\n",
       "      <td>1.836707e+01</td>\n",
       "      <td>1.537842e+00</td>\n",
       "      <td>4.882900e-01</td>\n",
       "      <td>3.367941e+00</td>\n",
       "      <td>5.184907e-01</td>\n",
       "      <td>9.820847e-01</td>\n",
       "      <td>2.702038e+01</td>\n",
       "      <td>2.274231e+00</td>\n",
       "      <td>1.074086e-01</td>\n",
       "      <td>1.566900e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.438480e-01</td>\n",
       "      <td>8.961200e-01</td>\n",
       "      <td>2.495838e+02</td>\n",
       "      <td>6.474767e+00</td>\n",
       "      <td>5.294762e-01</td>\n",
       "      <td>1.780782e+01</td>\n",
       "      <td>1.789592e+00</td>\n",
       "      <td>1.034641e-01</td>\n",
       "      <td>3.826759e+00</td>\n",
       "      <td>2.017579e+00</td>\n",
       "      <td>1.833529e-01</td>\n",
       "      <td>2.216359e+01</td>\n",
       "      <td>7.718454e-01</td>\n",
       "      <td>3.556511e-01</td>\n",
       "      <td>4.259435e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.000000e+02</td>\n",
       "      <td>-7.500000e+00</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-9.622000e+01</td>\n",
       "      <td>-6.500000e+01</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-7.510000e+02</td>\n",
       "      <td>-2.500000e+00</td>\n",
       "      <td>-1.250000e+00</td>\n",
       "      <td>-2.920000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.060000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.600000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.540000e+01</td>\n",
       "      <td>2.500000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.116667e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.800000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.280000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>2.720000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.016000e+01</td>\n",
       "      <td>2.500000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.151667e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.330000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.050000e+01</td>\n",
       "      <td>2.500000e+00</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>4.200000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.870000e+01</td>\n",
       "      <td>2.500000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.830000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>2.589281e+05</td>\n",
       "      <td>9.900000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.160100e+03</td>\n",
       "      <td>1.250000e+01</td>\n",
       "      <td>5.316000e+01</td>\n",
       "      <td>3.808000e+02</td>\n",
       "      <td>1.969900e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.169400e+03</td>\n",
       "      <td>2.500000e+00</td>\n",
       "      <td>1.250000e+00</td>\n",
       "      <td>1.002918e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           VendorID  passenger_count  trip_distance    RatecodeID  \\\n",
       "count  3.066766e+06     2.995023e+06   3.066766e+06  2.995023e+06   \n",
       "mean   1.730215e+00     1.362532e+00   3.847342e+00  1.497440e+00   \n",
       "std    4.438480e-01     8.961200e-01   2.495838e+02  6.474767e+00   \n",
       "min    1.000000e+00     0.000000e+00   0.000000e+00  1.000000e+00   \n",
       "25%    1.000000e+00     1.000000e+00   1.060000e+00  1.000000e+00   \n",
       "50%    2.000000e+00     1.000000e+00   1.800000e+00  1.000000e+00   \n",
       "75%    2.000000e+00     1.000000e+00   3.330000e+00  1.000000e+00   \n",
       "max    2.000000e+00     9.000000e+00   2.589281e+05  9.900000e+01   \n",
       "\n",
       "       payment_type   fare_amount         extra       mta_tax    tip_amount  \\\n",
       "count  3.066766e+06  3.066766e+06  3.066766e+06  3.066766e+06  3.066766e+06   \n",
       "mean   1.194483e+00  1.836707e+01  1.537842e+00  4.882900e-01  3.367941e+00   \n",
       "std    5.294762e-01  1.780782e+01  1.789592e+00  1.034641e-01  3.826759e+00   \n",
       "min    0.000000e+00 -9.000000e+02 -7.500000e+00 -5.000000e-01 -9.622000e+01   \n",
       "25%    1.000000e+00  8.600000e+00  0.000000e+00  5.000000e-01  1.000000e+00   \n",
       "50%    1.000000e+00  1.280000e+01  1.000000e+00  5.000000e-01  2.720000e+00   \n",
       "75%    1.000000e+00  2.050000e+01  2.500000e+00  5.000000e-01  4.200000e+00   \n",
       "max    4.000000e+00  1.160100e+03  1.250000e+01  5.316000e+01  3.808000e+02   \n",
       "\n",
       "       tolls_amount  improvement_surcharge  total_amount  \\\n",
       "count  3.066766e+06           3.066766e+06  3.066766e+06   \n",
       "mean   5.184907e-01           9.820847e-01  2.702038e+01   \n",
       "std    2.017579e+00           1.833529e-01  2.216359e+01   \n",
       "min   -6.500000e+01          -1.000000e+00 -7.510000e+02   \n",
       "25%    0.000000e+00           1.000000e+00  1.540000e+01   \n",
       "50%    0.000000e+00           1.000000e+00  2.016000e+01   \n",
       "75%    0.000000e+00           1.000000e+00  2.870000e+01   \n",
       "max    1.969900e+02           1.000000e+00  1.169400e+03   \n",
       "\n",
       "       congestion_surcharge   airport_fee      duration  \n",
       "count          2.995023e+06  2.995023e+06  3.066766e+06  \n",
       "mean           2.274231e+00  1.074086e-01  1.566900e+01  \n",
       "std            7.718454e-01  3.556511e-01  4.259435e+01  \n",
       "min           -2.500000e+00 -1.250000e+00 -2.920000e+01  \n",
       "25%            2.500000e+00  0.000000e+00  7.116667e+00  \n",
       "50%            2.500000e+00  0.000000e+00  1.151667e+01  \n",
       "75%            2.500000e+00  0.000000e+00  1.830000e+01  \n",
       "max            2.500000e+00  1.250000e+00  1.002918e+04  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellow_jan.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42544c1f",
   "metadata": {},
   "source": [
    "The standard deviation of the duration variable is 42.59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c374ab",
   "metadata": {},
   "source": [
    "## Checking for outliers \n",
    "```md\n",
    "we dont want bias estimations in our model/predictions.Outliers need to be removed in the dataset\n",
    "\n",
    "we need to check the distribution of the duration variable. \n",
    "\n",
    "There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c1abde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:32:10</td>\n",
       "      <td>2023-01-01 00:40:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:55:08</td>\n",
       "      <td>2023-01-01 01:01:27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>43</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:25:04</td>\n",
       "      <td>2023-01-01 00:37:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>14.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.90</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-01 00:03:48</td>\n",
       "      <td>2023-01-01 00:13:25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12.1</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>9.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-01 00:10:29</td>\n",
       "      <td>2023-01-01 00:21:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>107</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.68</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2023-01-01 00:32:10   2023-01-01 00:40:36              1.0   \n",
       "1         2  2023-01-01 00:55:08   2023-01-01 01:01:27              1.0   \n",
       "2         2  2023-01-01 00:25:04   2023-01-01 00:37:49              1.0   \n",
       "3         1  2023-01-01 00:03:48   2023-01-01 00:13:25              0.0   \n",
       "4         2  2023-01-01 00:10:29   2023-01-01 00:21:19              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag PULocationID DOLocationID  \\\n",
       "0           0.97         1.0                  N          161          141   \n",
       "1           1.10         1.0                  N           43          237   \n",
       "2           2.51         1.0                  N           48          238   \n",
       "3           1.90         1.0                  N          138            7   \n",
       "4           1.43         1.0                  N          107           79   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2          9.3   1.00      0.5        0.00           0.0   \n",
       "1             1          7.9   1.00      0.5        4.00           0.0   \n",
       "2             1         14.9   1.00      0.5       15.00           0.0   \n",
       "3             1         12.1   7.25      0.5        0.00           0.0   \n",
       "4             1         11.4   1.00      0.5        3.28           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \\\n",
       "0                    1.0         14.30                   2.5         0.00   \n",
       "1                    1.0         16.90                   2.5         0.00   \n",
       "2                    1.0         34.90                   2.5         0.00   \n",
       "3                    1.0         20.85                   0.0         1.25   \n",
       "4                    1.0         19.68                   2.5         0.00   \n",
       "\n",
       "    duration  \n",
       "0   8.433333  \n",
       "1   6.316667  \n",
       "2  12.750000  \n",
       "3   9.616667  \n",
       "4  10.833333  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellow_jan = yellow_jan[(yellow_jan.duration >= 1)& (yellow_jan.duration <= 60)]\n",
    "\n",
    "## print the data\n",
    "\n",
    "yellow_jan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e534ac",
   "metadata": {},
   "source": [
    "## What fraction of the records left after you dropped the outliers?\n",
    "```md\n",
    "This is a huge dataset actually \n",
    "\n",
    "```\n",
    "\n",
    "`3009173/3066766 = 0.98 == 98% of data is still left`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd95abe4",
   "metadata": {},
   "source": [
    "### One-hot encoding \n",
    "\n",
    "```md \n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "- Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will label encode them)\n",
    "- Fit a dictionary vectorizer\n",
    "- Get a feature matrix from it\n",
    "\n",
    "- What's the dimensionality of this matrix (number of columns)?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4751e519",
   "metadata": {},
   "source": [
    "```md\n",
    "One-hot encoding is a technique used to convert categorical variables into a numerical representation that can be used by machine learning algorithms. It is a common preprocessing step in data preparation.\n",
    "\n",
    "- In many machine learning algorithms, categorical variables cannot be directly used as input, as these algorithms typically operate on numerical data. \n",
    "\n",
    "- One-hot encoding transforms each categorical value into a binary vector, where each vector has a length equal to the number of unique categories in the variable. The vector contains all zeros except for a single one at the index corresponding to the category of the original value.\n",
    "\n",
    "- One-hot encoding allows machine learning models to effectively capture categorical information and handle it as numerical input. However, it increases the dimensionality of the data, especially when dealing with variables with many unique categories. This can impact computational efficiency and model performance, especially in cases where the number of categories is large relative to the number of observations.\n",
    "\n",
    "- To illustrate, let’s apply one-hot encoding to the pickup and dropoff location IDs. We’ll use only these two features for our model.\n",
    "\n",
    "```\n",
    "`reference: https://stephen137.github.io/posts/MLOps_Zoomcamp_Week_1/MLOps_Zoomcamp_Week_1.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9f984a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yellow_jan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n\u001b[1;32m      3\u001b[0m ohe \u001b[38;5;241m=\u001b[39m OneHotEncoder(handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, sparse\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m subset_df \u001b[38;5;241m=\u001b[39m \u001b[43myellow_jan\u001b[49m\u001b[38;5;241m.\u001b[39miloc[:, [\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m]]\n\u001b[1;32m      6\u001b[0m ohetransform \u001b[38;5;241m=\u001b[39m ohe\u001b[38;5;241m.\u001b[39mfit_transform(subset_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPULocationID\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m      8\u001b[0m ohetransform\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yellow_jan' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse= False)\n",
    "subset_df = yellow_jan.iloc[:, [7, 8]]\n",
    "\n",
    "ohetransform = ohe.fit_transform(subset_df[['PULocationID']])\n",
    "\n",
    "ohetransform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39f88849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3009173, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "array_lists = yellow_jan[categorical].to_numpy()\n",
    "                         \n",
    "# pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]}).to_numpy()\n",
    "\n",
    "# array([[1, 3],\n",
    "# [2, 4]])\n",
    "\n",
    "array_lists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7955bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## turn categorical column into a list of dictionaries to use as parameters for Vectorizer\n",
    "dict_lists = yellow_jan[categorical].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc6a76fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PULocationID': '161', 'DOLocationID': '141'}\n",
      "{'PULocationID': '43', 'DOLocationID': '237'}\n",
      "{'PULocationID': '48', 'DOLocationID': '238'}\n",
      "{'PULocationID': '138', 'DOLocationID': '7'}\n",
      "{'PULocationID': '107', 'DOLocationID': '79'}\n"
     ]
    }
   ],
   "source": [
    "## Iterate over the dict and check out the data\n",
    "for i in range(5):\n",
    "    print(dict_lists[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2609ada0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['161' '141']\n",
      "['43' '237']\n",
      "['48' '238']\n",
      "['138' '7']\n",
      "['107' '79']\n"
     ]
    }
   ],
   "source": [
    "## onehotenconder accepts array list  \n",
    "for item in array_lists[:5]:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a62250a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['161', '141'],\n",
       "       ['43', '237'],\n",
       "       ['48', '238'],\n",
       "       ...,\n",
       "       ['114', '239'],\n",
       "       ['230', '79'],\n",
       "       ['262', '143']], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert data to numpy array\n",
    "array_ohe = np.array(yellow_jan[categorical])\n",
    "array_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "311ca43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## instantiate a dictionary vectorizer \n",
    "## The DictVectorizer takes a little bit of memory, instead I will use OneHotEnconder instead \n",
    "dv = DictVectorizer()\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8251f38a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['161' '141']\n",
      "['43' '237']\n",
      "['48' '238']\n",
      "['138' '7']\n",
      "['107' '79']\n",
      "['161' '137']\n",
      "['239' '143']\n",
      "['142' '200']\n",
      "['164' '236']\n",
      "['141' '107']\n"
     ]
    }
   ],
   "source": [
    "## onehotenconder accepts array list  \n",
    "for item in array_lists[:10]:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0928b9e3",
   "metadata": {},
   "source": [
    "## OneHotEncoder data type\n",
    "\n",
    "```md\n",
    "It seems like your data X is a NumPy array containing pairs of values.\n",
    "- If you want to use scikit-learn's fit_transform method with this data, you'll need to convert it to a format that scikit-learn expects,\n",
    "- which is typically a 2D array-like object with shape (n_samples, n_features).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beba640",
   "metadata": {},
   "source": [
    "## Example of ohe\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X = [['Male', 1], ['Female', 3], ['Female', 2]]\n",
    "enc.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba99c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert to 2D array \n",
    "\n",
    "## convert to int\n",
    "\n",
    "## arr_reshaped = array.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3e92b19",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['1', '10', '100', '101', '102', '106', '107', '108', '109', '11',\n",
       "        '111', '112', '113', '114', '115', '116', '117', '118', '119',\n",
       "        '12', '120', '121', '122', '123', '124', '125', '126', '127',\n",
       "        '128', '129', '13', '130', '131', '132', '133', '134', '135',\n",
       "        '136', '137', '138', '139', '14', '140', '141', '142', '143',\n",
       "        '144', '145', '146', '147', '148', '149', '15', '150', '151',\n",
       "        '152', '153', '154', '155', '156', '157', '158', '159', '16',\n",
       "        '160', '161', '162', '163', '164', '165', '166', '167', '168',\n",
       "        '169', '17', '170', '171', '172', '173', '174', '175', '177',\n",
       "        '178', '179', '18', '180', '181', '182', '183', '184', '185',\n",
       "        '186', '187', '188', '189', '19', '190', '191', '192', '193',\n",
       "        '194', '195', '196', '197', '198', '199', '2', '20', '200', '201',\n",
       "        '202', '203', '205', '206', '207', '208', '209', '21', '210',\n",
       "        '211', '212', '213', '214', '215', '216', '217', '218', '219',\n",
       "        '22', '220', '221', '222', '223', '224', '225', '226', '227',\n",
       "        '228', '229', '23', '230', '231', '232', '233', '234', '235',\n",
       "        '236', '237', '238', '239', '24', '240', '241', '242', '243',\n",
       "        '244', '245', '246', '247', '248', '249', '25', '250', '251',\n",
       "        '252', '253', '254', '255', '256', '257', '258', '259', '26',\n",
       "        '260', '261', '262', '263', '264', '265', '28', '29', '3', '30',\n",
       "        '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40',\n",
       "        '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50',\n",
       "        '51', '52', '53', '54', '55', '56', '57', '58', '6', '60', '61',\n",
       "        '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71',\n",
       "        '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81',\n",
       "        '82', '83', '85', '86', '87', '88', '89', '9', '90', '91', '92',\n",
       "        '93', '94', '95', '96', '97', '98'], dtype=object),\n",
       " array(['1', '10', '100', '101', '102', '106', '107', '108', '109', '11',\n",
       "        '111', '112', '113', '114', '115', '116', '117', '118', '119',\n",
       "        '12', '120', '121', '122', '123', '124', '125', '126', '127',\n",
       "        '128', '129', '13', '130', '131', '132', '133', '134', '135',\n",
       "        '136', '137', '138', '139', '14', '140', '141', '142', '143',\n",
       "        '144', '145', '146', '147', '148', '149', '15', '150', '151',\n",
       "        '152', '153', '154', '155', '156', '157', '158', '159', '16',\n",
       "        '160', '161', '162', '163', '164', '165', '166', '167', '168',\n",
       "        '169', '17', '170', '171', '172', '173', '174', '175', '176',\n",
       "        '177', '178', '179', '18', '180', '181', '182', '183', '184',\n",
       "        '185', '186', '187', '188', '189', '19', '190', '191', '192',\n",
       "        '193', '194', '195', '196', '197', '198', '2', '20', '200', '201',\n",
       "        '202', '203', '204', '205', '206', '207', '208', '209', '21',\n",
       "        '210', '211', '212', '213', '214', '215', '216', '217', '218',\n",
       "        '219', '22', '220', '221', '222', '223', '224', '225', '226',\n",
       "        '227', '228', '229', '23', '230', '231', '232', '233', '234',\n",
       "        '235', '236', '237', '238', '239', '24', '240', '241', '242',\n",
       "        '243', '244', '245', '246', '247', '248', '249', '25', '250',\n",
       "        '251', '252', '253', '254', '255', '256', '257', '258', '259',\n",
       "        '26', '260', '261', '262', '263', '264', '265', '27', '28', '29',\n",
       "        '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39',\n",
       "        '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49',\n",
       "        '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59',\n",
       "        '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69',\n",
       "        '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79',\n",
       "        '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89',\n",
       "        '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fit the vectorizer and transform the data into a feature matrix\n",
    "## fm = dv.fit_transform(dict_lists)\n",
    "## ohe.fit_transform(array_lists, y=None)\n",
    "ohe = ohe.fit(array_ohe)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## convert the feature matrix to an array\n",
    "## fm_array = fm.toarray()\n",
    "##ohe_array = ohe.toarray()\n",
    "\n",
    "\n",
    "## print the dimensionality of the feature matrix\n",
    "# dimensionality = fm_array.shape\n",
    "# print(\"Dimensionality:\", dimensionality)\n",
    "\n",
    "ohe.categories_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b498767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fm.shape\n",
    "ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b81466",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "## fit the one hot encoder and transform the data into a feature matrix\n",
    "fme = ohe.fit_transform(array_lists, y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18db673",
   "metadata": {},
   "outputs": [],
   "source": [
    "fme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1441b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the feature matrix to an array\n",
    "\n",
    "fme.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c574288a",
   "metadata": {},
   "source": [
    "### customize pre-processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a03a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        df.tpep_dropoff_datetime = pd.to_datetime(df.tpep_dropoff_datetime)\n",
    "        df.tpep_pickup_datetime = pd.to_datetime(df.tpep_pickup_datetime)\n",
    "    elif filename.endswith('.parquet'):\n",
    "        df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e22c774",
   "metadata": {},
   "source": [
    "### Training a model\n",
    "\n",
    "Use the feature matrix from the previoud step to train a Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a34469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to a dictionary\n",
    "train_dicts = yellow_jan_22[categorical].to_dict(orient='records')\n",
    "\n",
    "# Instantiate a dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "\n",
    "# Set up trainign set\n",
    "X_train = dv.fit_transform(train_dicts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
